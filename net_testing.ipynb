{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import spectral.io.envi as envi\n",
    "import spectral as spy\n",
    "from spectral import open_image\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from math import floor\n",
    "from PIL import Image\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAvocado\u001b[m\u001b[m                           net_testing.ipynb\n",
      "\u001b[34mKeras_ds\u001b[m\u001b[m                          open_data.ipynb\n",
      "Specim IQ на русском.pdf          \u001b[34mopencv-python-4.5.3.56\u001b[m\u001b[m\n",
      "X(4843,3,100,100).pt              opencv.tar.gz\n",
      "X.pt                              png_cropped_dataset.png\n",
      "\u001b[34mdata_loaders_ssh\u001b[m\u001b[m                  png_cropped_dataset.png.png\n",
      "hdr_load_by_ssh.py                training.ipynb\n",
      "image_preprocessing.ipynb         y.pt\n",
      "keras.ipynb\n"
     ]
    }
   ],
   "source": [
    "!cd Avocado\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '0', '1', '4', '3', '2', '5']\n",
      "['.DS_Store', '0', '1', '4', '3', '2', '5']\n",
      "['.DS_Store', '0', '1', '4', '3', '2', '5']\n",
      "['.DS_Store', '0', '1', '4', '3', '2', '5']\n",
      "['.DS_Store', '0', '1', '4', '3', '2', '5']\n",
      "['.DS_Store', '0', '1', '4', '3', '2', '5']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "hdr_path = 'Avocado/hdr'\n",
    "png_path = 'Avocado/png'\n",
    "tensor_list = []\n",
    "target_list = []\n",
    "\n",
    "dir_list = os.listdir(hdr_path)\n",
    "for set_number in dir_list[1:]:\n",
    "    print(dir_list)\n",
    "    img_list = os.listdir(os.path.join(png_path, set_number))\n",
    "    if set_number=='4':\n",
    "        for img in img_list:\n",
    "            if os.path.exists(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\"):\n",
    "                image = cv2.imread(os.path.join(png_path, set_number, img))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                tensor_img = torch.tensor(image)\n",
    "                tensor_list.append(tensor_img[160:260, 73:173])\n",
    "                tensor_list.append(tensor_img[91:191, 171:271])\n",
    "                tensor_list.append(tensor_img[57:157, 263:363])\n",
    "                tensor_list.append(tensor_img[133:233, 335:435])\n",
    "                tensor_list.append(tensor_img[177:277, 255:355])\n",
    "                tensor_list.append(tensor_img[238:338, 167:267])\n",
    "                tensor_list.append(tensor_img[291:391, 73:173])\n",
    "                tensor_list.append(tensor_img[362:462, 174:274])\n",
    "                tensor_list.append(tensor_img[303:403, 272:372])\n",
    "                tensor_list.append(tensor_img[242:342, 373:473])\n",
    "                spectr = envi.open(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\", image = os.path.join(hdr_path, set_number, img[:-4])+\".hdr\")\n",
    "                date = spectr.metadata['acquisition date']\n",
    "                for i in range(10):\n",
    "                    target_list.append(f\"{set_number}\"+date)\n",
    "\n",
    "\n",
    "    elif set_number=='3':\n",
    "        for img in img_list:\n",
    "            if os.path.exists(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\"):\n",
    "                image = cv2.imread(os.path.join(png_path, set_number, img))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                tensor_img = torch.tensor(image)\n",
    "                tensor_list.append(tensor_img[170:470, 86:386])\n",
    "                spectr = envi.open(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\", image = os.path.join(hdr_path, set_number, img[:-4])+\".hdr\")\n",
    "                date = spectr.metadata['acquisition date']\n",
    "                target_list.append(f\"{set_number}\"+date)\n",
    "\n",
    "\n",
    "    elif set_number=='2':\n",
    "        for img in img_list:\n",
    "            if os.path.exists(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\"):\n",
    "                image = cv2.imread(os.path.join(png_path, set_number, img))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                tensor_img = torch.tensor(image)\n",
    "                tensor_list.append(tensor_img[63:363, 260:510])\n",
    "                tensor_list.append(tensor_img[57:307, :250])\n",
    "                spectr = envi.open(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\", image = os.path.join(hdr_path, set_number, img[:-4])+\".hdr\")\n",
    "                date = spectr.metadata['acquisition date']\n",
    "                for i in range(2):\n",
    "                    target_list.append(f\"{set_number}\"+date)\n",
    "\n",
    "    elif set_number=='1':\n",
    "        for img in img_list:\n",
    "            if os.path.exists(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\"):\n",
    "                image = cv2.imread(os.path.join(png_path, set_number, img))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                tensor_img = torch.tensor(image)\n",
    "                tensor_list.append(tensor_img[135:475, :230])\n",
    "                tensor_list.append(tensor_img[135:475, 270:512])\n",
    "                spectr = envi.open(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\", image = os.path.join(hdr_path, set_number, img[:-4])+\".hdr\")\n",
    "                date = spectr.metadata['acquisition date']\n",
    "                for i in range(2):\n",
    "                    target_list.append(f\"{set_number}\"+date)\n",
    "\n",
    "    elif set_number=='0':\n",
    "        for img in img_list:\n",
    "            if os.path.exists(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\"):\n",
    "                image = cv2.imread(os.path.join(png_path, set_number, img))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                tensor_img = torch.tensor(image)\n",
    "                tensor_list.append(tensor_img[20:390, :220])\n",
    "                tensor_list.append(tensor_img[:370, 240:490])\n",
    "                spectr = envi.open(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\", image = os.path.join(hdr_path, set_number, img[:-4])+\".hdr\")\n",
    "                date = spectr.metadata['acquisition date']\n",
    "                for i in range(2):\n",
    "                    target_list.append(f\"{set_number}\"+date)\n",
    "\n",
    "    elif set_number=='5':\n",
    "        for img in img_list:\n",
    "            if os.path.exists(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\"):\n",
    "                image = cv2.imread(os.path.join(png_path, set_number, img))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                tensor_img = torch.tensor(image)\n",
    "                tensor_list.append(tensor_img[98:378, 24:248])\n",
    "                tensor_list.append(tensor_img[107:387, 258:488])\n",
    "                spectr = envi.open(os.path.join(hdr_path, set_number, img[:-4])+\".hdr\", image = os.path.join(hdr_path, set_number, img[:-4])+\".hdr\")\n",
    "                date = spectr.metadata['acquisition date']\n",
    "                for i in range(2):\n",
    "                    target_list.append(f\"{set_number}\"+date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4843, 4843)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensor_list), len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date2days(Y: list):\n",
    "    Y_ser = pd.Series(Y)\n",
    "    Y_group = Y_ser.apply(lambda x: x[0])\n",
    "    Y_date = Y_ser.apply(lambda x: x[1:])\n",
    "    Y_df = pd.DataFrame({\"group\": Y_group, \"date\": Y_date})\n",
    "    Y_df.date = Y_df.date.apply(lambda x: datetime.strptime(x, \"%d-%m-%Y\"))\n",
    "    min_date = []\n",
    "    for i in range(0, 6):\n",
    "        min_date.append(Y_df[Y_df.group==str(i)].date.min())\n",
    "    day_number = Y_df.date\n",
    "    for i in range(0, 6):\n",
    "        day_number[Y_df.group==str(i)] = Y_df.date[Y_df.group==str(i)].apply(lambda x: x-min_date[i])\n",
    "    return day_number.apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = torch.Tensor(date2days(target_list).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = torch.zeros((4843, 100, 100, 3))\n",
    "\n",
    "for i in range(4843):\n",
    "    image = torch.Tensor.numpy(tensor_list[i])\n",
    "    resized_image = cv2.resize(image, (100, 100))\n",
    "    normalized_image = cv2.normalize(resized_image.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    new_images[i] = torch.Tensor(normalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m N_ROWS \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      3\u001b[0m ROW_IMG \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 5\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, ROW_IMG \u001b[39m*\u001b[39m N_ROWS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m      7\u001b[0m     index \u001b[39m=\u001b[39m randrange(\u001b[39m0\u001b[39m, \u001b[39m4843\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "N_ROWS = 5\n",
    "ROW_IMG = 10\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(1, ROW_IMG * N_ROWS + 1):\n",
    "    index = randrange(0, 4843)\n",
    "    plt.subplot(N_ROWS, ROW_IMG, i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(new_images[index])\n",
    "    plt.title(int(np.array(Target)[index]))\n",
    "fig.suptitle('PNG Dataset - preview');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Tensor, 'X.pt')\n",
    "torch.save(Target, 'y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = torch.zeros((4843, 100, 100, 3))\n",
    "\n",
    "for i in range(4843):\n",
    "    image = torch.Tensor.numpy(tensor_list[i])\n",
    "    resized_image = cv2.resize(image, (100, 100))\n",
    "    normalized_image = cv2.normalize(resized_image.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    new_images[i] = torch.Tensor(normalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = new_images\n",
    "torch.save(Tensor, \"X(4843,3,100,100).pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "for i in range(4843):\n",
    "    array = new_images[i].numpy()\n",
    "    classs = int(Target[i])\n",
    "    image = Image.fromarray(np.uint8(array* 255))\n",
    "    image.save(f'Keras_ds/{classs}/{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"mkdir Keras_ds\")\n",
    "for i in range(10):\n",
    "    os.system(f\"mkdir Keras_ds/{i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce4612f5cc43648f503aa8eb7f2a41c796d0d330c9f537245bf6e2f2c567c915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
